{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Algorithms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CART\n",
    "def impurity(x):\n",
    "    a=x**2+(1-x)**2\n",
    "    return 1-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4991073199761952"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GINI INDEX\n",
    "#range~(0,0.5)\n",
    "#before split\n",
    "impurity(37/71)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2790847820609724"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#after split\n",
    "0.5*(impurity(1/7)+impurity(7/36))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training data\n",
    "validation data(prune) avoid overfitting pick k(terminal nodes)\n",
    "testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pro: easy to explain\n",
    "Con: computationally expensive\n",
    "    large datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regression Tree\n",
    "#impurity use RMSE(to make a split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN k-nearest-neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training data (labels)\n",
    "valid--pick K(K=5)\n",
    "\n",
    "predictivde model:\n",
    "training data: total_train=train+valid\n",
    "K=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how to decide new label?\n",
    "1/3*(0+0+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-7995ebb11d82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#model fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#generate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "#model fitting\n",
    "X\n",
    "y\n",
    "knn=KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X,y) #generate the model\n",
    "#model predicting\n",
    "y_pred=knn.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Traing and Testing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y, test_size=0.3,random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets as ds\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear regression\n",
    "OLS: sum squre of residual \n",
    "    \n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train,y_train)#generate the model\n",
    "y_pred = reg.predict(X_pred)\n",
    "\n",
    "# Print R^2 \n",
    "print(reg.score(X_train,y_train))\n",
    "\n",
    "# Plot regression line\n",
    "plt.plot(X_pred, y_pred, color='black', linewidth=3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation used for pick parameter within the model(knn/tree)\n",
    "#有了在指定参数下的model（knn中选定k=3），再测在validation上的average accuracy\n",
    "#!!!最后选的是model的结构:\n",
    "    linear regression(how many x involved)\n",
    "    tree(how many terminal nodes)...\n",
    "\n",
    "cv=5(number of folds)\n",
    "k=3:(acc1+acc2+...+acc5)/5\n",
    "k=4:(acc1+acc2+...+acc5)/5\n",
    "Pro: avoid relying on train/test split\n",
    "Con: too much computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "reg = LinearRegression()\n",
    "\n",
    "cv_scores = cross_val_score(reg,X,y,cv=5)\n",
    "\n",
    "print(\"Average 5-Fold CV Score: {}\".format(np.mean(cv_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge/Lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#avoid parameter too big\n",
    "Ridge: Loss Function = OLS Loss Function + sum((ai**2))\n",
    "\n",
    "#Lasso 可以把不重要的变量，coefficient变为0，作为high dimension中选取关键变量\n",
    "Lasso: Loss Function = OLS Loss Function + sum(np.abs(ai))  #feature selection, as unimportant ai can turn to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso(alpha=0.4,normalize=True)\n",
    "lasso.fit(X,y)\n",
    "\n",
    "# Compute and print the coefficients\n",
    "lasso_coef = lasso.coef_\n",
    "print(lasso_coef)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Setup the array of alphas and lists to store scores\n",
    "alpha_space = np.logspace(-4, 0, 50)   #不同alpha值\n",
    "ridge_scores = []\n",
    "ridge_scores_std = []\n",
    "\n",
    "# Create a ridge regressor: ridge\n",
    "ridge = Ridge(normalize=True)\n",
    "\n",
    "for alpha in alpha_space:\n",
    "    ridge.alpha = alpha\n",
    "    ridge_cv_scores = cross_val_score(ridge,X,y,cv=10) #同一个alpha下，10个值\n",
    "    ridge_scores.append(np.mean(ridge_cv_scores))\n",
    "    ridge_scores_std.append(np.std(ridge_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
